{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkDor8NqN33y"
   },
   "source": [
    "# Early Stopping\n",
    "## MLP (MNIST, Tensorflow) with Early Stopping\n",
    "In this tutorial, we will apply early stopping on MNIST MLP tensorflow code.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w5rLtNjtN061"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u47ESDcROF7f"
   },
   "source": [
    "## MLP Architecture\n",
    "here is the overview of MLP(Multi Layer Perceptron) architecture we will implement with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "PeXbRuuTOL0a",
    "outputId": "3b588cb0-3479-407c-e948-647969d61d61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIClBFFUOsmv"
   },
   "source": [
    "## Collect MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WU8HUPpDOb2P",
    "outputId": "d6e8a6bb-a387-4e9a-8926-bcb4f2c331c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZsS0b_EOwKm",
    "outputId": "b9f8888e-d9e5-43fe-c0cc-9cd1036bc9e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cu4qIhdPZIt"
   },
   "source": [
    "train data has 60000 samples\n",
    "\n",
    "test data has 10000 samples\n",
    "\n",
    "every data is 28 * 28 pixels\n",
    "\n",
    "below image shows 28*28 pixel image sample for hand written number '0' from MNIST data.\n",
    "\n",
    "MNIST is gray scale image [0 to 255] for hand written number.\n",
    "\n",
    "![0.png](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "242Xd_u0P2OI"
   },
   "source": [
    "## Split train data into train and validation data\n",
    "Validation during training gives advantages below,\n",
    "\n",
    "1) check if train goes well based on validation score\n",
    "\n",
    "2) apply early stopping when validation score doesn't improve while train score goes up (overcome overfitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J3N313I9PROl"
   },
   "outputs": [],
   "source": [
    "x_val  = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_val  = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyLcFwWPQHuW",
    "outputId": "b44b35df-ce94-42e8-eee6-c11839484784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data has 50000 samples\n",
      "every train data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"train data has \" + str(x_train.shape[0]) + \" samples\")\n",
    "print(\"every train data is \" + str(x_train.shape[1]) \n",
    "      + \" * \" + str(x_train.shape[2]) + \" image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWg4fD2yQOcN",
    "outputId": "168e058e-7440-4a0d-89ad-121c436b731a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data has 10000 samples\n",
      "every train data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"validation data has \" + str(x_val.shape[0]) + \" samples\")\n",
    "print(\"every train data is \" + str(x_val.shape[1]) \n",
    "      + \" * \" + str(x_train.shape[2]) + \" image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td1Bf2CDQR36",
    "outputId": "eb4f2d87-2d53-48d3-a2cb-d86ef7428a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# sample to show gray scale values\n",
    "print(x_train[0][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waGii20CQbby"
   },
   "source": [
    "\n",
    "each train data has its label 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0gpLRWaQU1W",
    "outputId": "a2a67fcc-ab54-4e74-a17f-422333f2a0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "# sample to show labels for first train data to 10th train data\n",
    "print(y_train[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT8BbxswQq74"
   },
   "source": [
    "test data has 10000 samples\n",
    "\n",
    "every test data is 28 * 28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m54Yk5cQQefL",
    "outputId": "b8049ced-1ac9-4b22-ed00-eb66d1035e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data has 10000 samples\n",
      "every test data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
    "print(\"every test data is \" + str(x_test.shape[1]) \n",
    "      + \" * \" + str(x_test.shape[2]) + \" image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao_wFAElRHla"
   },
   "source": [
    "## Reshape\n",
    "In order to fully connect all pixels to hidden layer,\n",
    "\n",
    "we will reshape (28, 28) into (28x28,1) shape.\n",
    "\n",
    "It means we flatten row x column shape to an array having 28x28 (756) items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "C0mtzCtGQ5WL",
    "outputId": "ac2fa160-2dc9-47f9-a7ab-683f2d0d4808"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/reshape_mnist.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/reshape_mnist.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p779YWCaRWvc",
    "outputId": "5c9e7ad0-a916-4edd-f707-e772977b46d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = x_train.reshape(50000, 784)\n",
    "x_val = x_val.reshape(10000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxDARoxMSaA6",
    "outputId": "759d8a12-007b-40a9-b28c-67a0fd976b83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hWCh3kvSoL_"
   },
   "source": [
    "## Normalize data\n",
    "\n",
    "normalization usually helps faster learning speed, better performance\n",
    "by reducing variance and giving same range to all input features.\n",
    "since MNIST data set all input has 0 to 255, normalization only helps reducing variances.\n",
    "it turned out normalization is better than standardization for MNIST data with my MLP architeture,\n",
    "I believe this is because relu handles 0 differently on both feed forward and back propagation.\n",
    "handling 0 differently is important for MNIST, since 1-255 means there is some hand written,\n",
    "while 0 means no hand written on that pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lZH13-H1SdMX"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDsFs9qQSx3l"
   },
   "source": [
    "\n",
    "## label to one hot encoding value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "blmqheXeSuNX"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNHAouUlS9rb",
    "outputId": "8242dd3a-7ddb-4293-a337-b3b450e88b64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_d_7WbmaTJRu"
   },
   "source": [
    "## Tensorflow MLP Graph\n",
    "Let's implement the MLP graph with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "nMg5geldTFZg",
    "outputId": "f5487fd3-6c2a-4731-a23d-13cd1628013b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/simple_mlp_mnist.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yz1FUYnJTvqf",
    "outputId": "38861044-a62c-4a3e-d627-2cd248e7c376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SaDisr5BTOii"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VZXz1zz0Tbiw"
   },
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    # hidden layer1\n",
    "    w1 = tf.Variable(tf.random_uniform([784,256]))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    # hidden layer2\n",
    "    w2 = tf.Variable(tf.random_uniform([256,128]))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    # output layer\n",
    "    w3 = tf.Variable(tf.random_uniform([128,10]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logits= tf.matmul(h2, w3) + b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rV9MHvK9T4m_"
   },
   "outputs": [],
   "source": [
    "\n",
    "logits = mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "k25RNHwST8Sb"
   },
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MeY-_ZW5UBbC"
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iC0jc6RUGXf"
   },
   "source": [
    "## Early Stopping\n",
    "When validation accuracy doesn't improve while train accuracy keep improves,\n",
    "\n",
    "we can early stop the train in order to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "XJxlxQ53UEKq",
    "outputId": "c125bc05-c793-49d8-ffcf-38c3973baae4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/early_stop.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/early_stop.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3jCmVIOfUNvG"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# train hyperparameters\n",
    "epoch_cnt = 300\n",
    "batch_size = 1000\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "earlystop_threshold = 5\n",
    "earlystop_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msdWafNtUZZo",
    "outputId": "0143d75b-ecc7-4847-88d7-5c29f9daf4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train acc: 0.18672, val acc: 0.1883\n",
      "epoch: 1, train acc: 0.76362, val acc: 0.7847\n",
      "epoch: 2, train acc: 0.8562, val acc: 0.8719\n",
      "epoch: 3, train acc: 0.87398, val acc: 0.8838\n",
      "epoch: 4, train acc: 0.8886, val acc: 0.8942\n",
      "epoch: 5, train acc: 0.89422, val acc: 0.9018\n",
      "epoch: 6, train acc: 0.89502, val acc: 0.9011\n",
      "overfitting warning: 0\n",
      "epoch: 7, train acc: 0.89116, val acc: 0.897\n",
      "epoch: 8, train acc: 0.88474, val acc: 0.8911\n",
      "epoch: 9, train acc: 0.88886, val acc: 0.8937\n",
      "overfitting warning: 0\n",
      "epoch: 10, train acc: 0.87132, val acc: 0.8771\n",
      "epoch: 11, train acc: 0.84648, val acc: 0.8548\n",
      "epoch: 12, train acc: 0.90144, val acc: 0.904\n",
      "epoch: 13, train acc: 0.90438, val acc: 0.9079\n",
      "epoch: 14, train acc: 0.91562, val acc: 0.916\n",
      "epoch: 15, train acc: 0.90426, val acc: 0.9032\n",
      "epoch: 16, train acc: 0.91928, val acc: 0.9197\n",
      "epoch: 17, train acc: 0.8988, val acc: 0.898\n",
      "epoch: 18, train acc: 0.87938, val acc: 0.8846\n",
      "epoch: 19, train acc: 0.84624, val acc: 0.8573\n",
      "epoch: 20, train acc: 0.91484, val acc: 0.9158\n",
      "overfitting warning: 0\n",
      "epoch: 21, train acc: 0.92252, val acc: 0.9213\n",
      "epoch: 22, train acc: 0.9169, val acc: 0.9171\n",
      "epoch: 23, train acc: 0.927, val acc: 0.9238\n",
      "epoch: 24, train acc: 0.92244, val acc: 0.9182\n",
      "epoch: 25, train acc: 0.8757, val acc: 0.8787\n",
      "epoch: 26, train acc: 0.9133, val acc: 0.912\n",
      "overfitting warning: 0\n",
      "epoch: 27, train acc: 0.93202, val acc: 0.924\n",
      "epoch: 28, train acc: 0.92512, val acc: 0.9197\n",
      "epoch: 29, train acc: 0.93654, val acc: 0.9308\n",
      "epoch: 30, train acc: 0.93904, val acc: 0.9299\n",
      "overfitting warning: 0\n",
      "epoch: 31, train acc: 0.94242, val acc: 0.9353\n",
      "epoch: 32, train acc: 0.93804, val acc: 0.928\n",
      "epoch: 33, train acc: 0.93546, val acc: 0.9276\n",
      "epoch: 34, train acc: 0.94122, val acc: 0.9325\n",
      "overfitting warning: 0\n",
      "epoch: 35, train acc: 0.94418, val acc: 0.9343\n",
      "overfitting warning: 1\n",
      "epoch: 36, train acc: 0.92734, val acc: 0.9174\n",
      "epoch: 37, train acc: 0.9235, val acc: 0.915\n",
      "epoch: 38, train acc: 0.92932, val acc: 0.9198\n",
      "overfitting warning: 0\n",
      "epoch: 39, train acc: 0.92972, val acc: 0.9201\n",
      "overfitting warning: 1\n",
      "epoch: 40, train acc: 0.94768, val acc: 0.9375\n",
      "epoch: 41, train acc: 0.95474, val acc: 0.9413\n",
      "epoch: 42, train acc: 0.95538, val acc: 0.9391\n",
      "overfitting warning: 0\n",
      "epoch: 43, train acc: 0.9484, val acc: 0.933\n",
      "epoch: 44, train acc: 0.93748, val acc: 0.9208\n",
      "epoch: 45, train acc: 0.95688, val acc: 0.939\n",
      "overfitting warning: 0\n",
      "epoch: 46, train acc: 0.95806, val acc: 0.9415\n",
      "epoch: 47, train acc: 0.9505, val acc: 0.9342\n",
      "epoch: 48, train acc: 0.9441, val acc: 0.927\n",
      "epoch: 49, train acc: 0.94918, val acc: 0.9308\n",
      "overfitting warning: 0\n",
      "epoch: 50, train acc: 0.94182, val acc: 0.9263\n",
      "epoch: 51, train acc: 0.95634, val acc: 0.9398\n",
      "overfitting warning: 0\n",
      "epoch: 52, train acc: 0.95354, val acc: 0.9342\n",
      "epoch: 53, train acc: 0.94926, val acc: 0.9334\n",
      "epoch: 54, train acc: 0.9438, val acc: 0.9284\n",
      "epoch: 55, train acc: 0.95454, val acc: 0.9376\n",
      "overfitting warning: 0\n",
      "epoch: 56, train acc: 0.96456, val acc: 0.9445\n",
      "epoch: 57, train acc: 0.97312, val acc: 0.9513\n",
      "epoch: 58, train acc: 0.97886, val acc: 0.9558\n",
      "epoch: 59, train acc: 0.97126, val acc: 0.9488\n",
      "epoch: 60, train acc: 0.97456, val acc: 0.952\n",
      "overfitting warning: 0\n",
      "epoch: 61, train acc: 0.97434, val acc: 0.9522\n",
      "epoch: 62, train acc: 0.97288, val acc: 0.9539\n",
      "epoch: 63, train acc: 0.977, val acc: 0.9568\n",
      "epoch: 64, train acc: 0.96998, val acc: 0.9473\n",
      "epoch: 65, train acc: 0.9835, val acc: 0.9581\n",
      "epoch: 66, train acc: 0.98034, val acc: 0.9545\n",
      "epoch: 67, train acc: 0.98284, val acc: 0.9551\n",
      "overfitting warning: 0\n",
      "epoch: 68, train acc: 0.98242, val acc: 0.9563\n",
      "epoch: 69, train acc: 0.9799, val acc: 0.9569\n",
      "epoch: 70, train acc: 0.98294, val acc: 0.9579\n",
      "overfitting warning: 0\n",
      "epoch: 71, train acc: 0.97592, val acc: 0.9508\n",
      "epoch: 72, train acc: 0.97662, val acc: 0.9526\n",
      "overfitting warning: 0\n",
      "epoch: 73, train acc: 0.9823, val acc: 0.9543\n",
      "overfitting warning: 1\n",
      "epoch: 74, train acc: 0.981, val acc: 0.9515\n",
      "epoch: 75, train acc: 0.98502, val acc: 0.9565\n",
      "overfitting warning: 0\n",
      "epoch: 76, train acc: 0.98952, val acc: 0.9619\n",
      "epoch: 77, train acc: 0.98914, val acc: 0.9605\n",
      "epoch: 78, train acc: 0.98332, val acc: 0.9551\n",
      "epoch: 79, train acc: 0.98948, val acc: 0.9602\n",
      "overfitting warning: 0\n",
      "epoch: 80, train acc: 0.99142, val acc: 0.9628\n",
      "epoch: 81, train acc: 0.98446, val acc: 0.958\n",
      "epoch: 82, train acc: 0.98526, val acc: 0.9582\n",
      "overfitting warning: 0\n",
      "epoch: 83, train acc: 0.99182, val acc: 0.9625\n",
      "overfitting warning: 1\n",
      "epoch: 84, train acc: 0.98876, val acc: 0.9605\n",
      "epoch: 85, train acc: 0.99348, val acc: 0.9617\n",
      "overfitting warning: 0\n",
      "epoch: 86, train acc: 0.9915, val acc: 0.9579\n",
      "overfitting warning: 1\n",
      "epoch: 87, train acc: 0.98226, val acc: 0.9519\n",
      "epoch: 88, train acc: 0.99454, val acc: 0.9624\n",
      "overfitting warning: 0\n",
      "epoch: 89, train acc: 0.9948, val acc: 0.9649\n",
      "epoch: 90, train acc: 0.98906, val acc: 0.9598\n",
      "epoch: 91, train acc: 0.99768, val acc: 0.9669\n",
      "epoch: 92, train acc: 0.99766, val acc: 0.9648\n",
      "overfitting warning: 0\n",
      "epoch: 93, train acc: 0.99898, val acc: 0.9674\n",
      "epoch: 94, train acc: 0.99764, val acc: 0.965\n",
      "overfitting warning: 0\n",
      "epoch: 95, train acc: 0.99838, val acc: 0.9651\n",
      "overfitting warning: 1\n",
      "epoch: 96, train acc: 0.99298, val acc: 0.963\n",
      "overfitting warning: 2\n",
      "epoch: 97, train acc: 0.99878, val acc: 0.9662\n",
      "overfitting warning: 3\n",
      "epoch: 98, train acc: 0.99706, val acc: 0.9636\n",
      "overfitting warning: 4\n",
      "epoch: 99, train acc: 0.99002, val acc: 0.9564\n",
      "early stopped on 99\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    prev_train_acc = 0.0\n",
    "    max_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.\n",
    "        start = 0; end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            _, loss = sess.run([train_op, loss_op], \n",
    "                               feed_dict={x: x_train[start: end], y: y_train[start: end]})\n",
    "            start += batch_size; end += batch_size\n",
    "            # Compute train average loss\n",
    "            avg_loss += loss / iteration\n",
    "            \n",
    "        # Validate model\n",
    "        preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        # train accuracy\n",
    "        cur_train_acc = accuracy.eval({x: x_train, y: y_train})\n",
    "        # validation accuarcy\n",
    "        cur_val_acc = accuracy.eval({x: x_val, y: y_val})\n",
    "        # validation loss\n",
    "        cur_val_loss = loss_op.eval({x: x_val, y: y_val})\n",
    "        \n",
    "        print(\"epoch: \"+str(epoch)+\n",
    "              \", train acc: \" + str(cur_train_acc) +\n",
    "              \", val acc: \" + str(cur_val_acc) )\n",
    "              #', train loss: '+str(avg_loss)+\n",
    "              #', val loss: '+str(cur_val_loss))\n",
    "        \n",
    "        if cur_val_acc < max_val_acc:\n",
    "            if cur_train_acc > prev_train_acc or cur_train_acc > 0.99:\n",
    "                if earlystop_cnt == earlystop_threshold:\n",
    "                    print(\"early stopped on \"+str(epoch))\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"overfitting warning: \"+str(earlystop_cnt))\n",
    "                    earlystop_cnt += 1\n",
    "            else:\n",
    "                earlystop_cnt = 0\n",
    "        else:\n",
    "            earlystop_cnt = 0\n",
    "            max_val_acc = cur_val_acc\n",
    "            # Save the variables to file.\n",
    "            save_path = saver.save(sess, \"model/model.ckpt\")\n",
    "        prev_train_acc = cur_train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZTwFvPmV22g"
   },
   "source": [
    "\n",
    "## Testing with the best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2q73QVPNUzU0",
    "outputId": "6d3c7b80-3ab6-4115-d237-65a194442ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "[Test Accuracy] : 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Start testing\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"model/model.ckpt\")\n",
    "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ucxm1FvV8RK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "early_Stoping_in_MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
